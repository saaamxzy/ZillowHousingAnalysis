{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us state name -> 2-letter state code\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY',\n",
    "    'American Samoa': 'AS',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Federated States of Micronesia': 'FM',\n",
    "    'Guam': 'GU',\n",
    "    'Marshall Islands': 'MH',\n",
    "    'Northern Mariana Islands': 'MP',\n",
    "    'Palau': 'PW',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Virgin Islands': 'VI',\n",
    "    # added values\n",
    "    'United States': 'United States'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load population info for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pop(filename):\n",
    "    # begin time\n",
    "    print('processing ' + filename)\n",
    "    t0 = time.time()\n",
    "    # prepare\n",
    "    attributes = ['state_code','state_name','year','population']\n",
    "    original_df = pd.io.excel.read_excel(filename, sheet_name=0)\n",
    "    raw_df = original_df[['NAME','POPESTIMATE2010','POPESTIMATE2011','POPESTIMATE2012','POPESTIMATE2013','POPESTIMATE2014','POPESTIMATE2015','POPESTIMATE2016','POPESTIMATE2017','POPESTIMATE2018']]\n",
    "    raw_df = raw_df[~raw_df['NAME'].isin(['Northeast Region','Midwest Region','South Region','West Region'])]\n",
    "    df_mat = []\n",
    "    def unwind(series):\n",
    "        state_name = series[0]\n",
    "        state_code = us_state_abbrev[state_name]\n",
    "        for j in range(1, len(series)):\n",
    "            if pd.isnull(series[j]):\n",
    "                value = None\n",
    "            else:\n",
    "                value = series[j]\n",
    "            df_mat.append([ state_code, state_name, 2009 + j, value ])\n",
    "    # apply map\n",
    "    raw_df.apply(unwind, axis=1)\n",
    "    temp_df = pd.DataFrame(df_mat, columns=attributes)\n",
    "    # end time\n",
    "    print('time used to process ' + str(filename) + ': ' + str( int(time.time()-t0) ) + 's')\n",
    "    # return\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/nst-est2018-alldata.xlsx\n",
      "time used to process rawdata/nst-est2018-alldata.xlsx: 0s\n"
     ]
    }
   ],
   "source": [
    "pop_df = load_pop('rawdata/nst-est2018-alldata.xlsx')\n",
    "pop_df.to_csv('processed_data/final_pop.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metro & mhi info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_dict = {} # dictionary: RegionName -> metro_id\n",
    "metro_df_mat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metro_mhi(filename):\n",
    "    # begin time\n",
    "    print('processing ' + filename)\n",
    "    t0 = time.time()\n",
    "    # prepare\n",
    "    attributes = ['id','time_stamp','income']\n",
    "    original_df = pd.read_csv(filename, encoding=\"ISO-8859-1\")\n",
    "    raw_df = original_df.drop(columns=['SizeRank'])\n",
    "    mhi_df_mat = []\n",
    "    def metro_mhi(series):\n",
    "        # series: [metro_id, RegionName, timestamps...]\n",
    "        name_code = [ x.strip() for x in series[1].split(',') ]\n",
    "        metro_df_mat.append([ series[0], series[1], name_code[-1] ])\n",
    "        metro_dict[series[1]] = series[0]\n",
    "        for j in range(2,len(series)):\n",
    "            if pd.isnull(series[j]):\n",
    "                income = None\n",
    "            else:\n",
    "                income = int(series[j])\n",
    "            mhi_df_mat.append([ series[0], series.index[j], income ])\n",
    "    # apply to df\n",
    "    raw_df.apply(metro_mhi, axis=1)\n",
    "    temp_df = pd.DataFrame(mhi_df_mat, columns=attributes)\n",
    "    # end time\n",
    "    print('time used to process ' + str(filename) + ': ' + str( int(time.time()-t0) ) + 's')\n",
    "    # return\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/Affordability_Income_2018Q4.csv\n",
      "time used to process rawdata/Affordability_Income_2018Q4.csv: 4s\n"
     ]
    }
   ],
   "source": [
    "mhi_df = load_metro_mhi('rawdata/Affordability_Income_2018Q4.csv')\n",
    "mhi_df.to_csv('processed_data/final_mhi.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SalesCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sales(filename,property_type):\n",
    "    # begin time\n",
    "    print('processing ' + filename)\n",
    "    t0 = time.time()\n",
    "    # prepare\n",
    "    attributes = ['metro_id', 'property_type', 'time_stamp', 'num_sales' ]\n",
    "    original_df = pd.read_csv(filename, encoding=\"ISO-8859-1\")\n",
    "    raw_df = original_df.drop(columns=['SizeRank'])\n",
    "    df_mat = []\n",
    "    def unwind(series):\n",
    "        # series: metro_id, RegionName, timestamp\n",
    "        # for metro info\n",
    "        metro_dict[series[1]] = series[0]\n",
    "        name_code = [ x.strip() for x in series[1].split(',') ]\n",
    "        metro_df_mat.append([ series[0], series[1], name_code[-1] ])\n",
    "        # for SalesCount info\n",
    "        metro_id = series[0]\n",
    "        for j in range(2, len(series)):\n",
    "            if pd.isnull(series[j]):\n",
    "                value = None\n",
    "            else:\n",
    "                value = int(series[j])\n",
    "            df_mat.append([ int(metro_id), property_type, series.index[j], value ])\n",
    "    # apply map\n",
    "    raw_df.apply(unwind, axis=1)\n",
    "    temp_df = pd.DataFrame(df_mat, columns=attributes)\n",
    "    # end time\n",
    "    print('time used to process ' + str(filename) + ': ' + str( int(time.time()-t0) ) + 's')\n",
    "    # return\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/Sale_Counts_Seas_Adj_Msa.csv\n",
      "time used to process rawdata/Sale_Counts_Seas_Adj_Msa.csv: 2s\n"
     ]
    }
   ],
   "source": [
    "sales_df = load_sales('rawdata/Sale_Counts_Seas_Adj_Msa.csv','allhomes')\n",
    "sales_df.to_csv('processed_data/final_SalesCount.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load price-to-rent ratio & sale-to-list ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for price-to-rent ratio\n",
    "def load_ptr(filename, attributes):\n",
    "    # begin time\n",
    "    print('processing ' + filename)\n",
    "    t0 = time.time()\n",
    "    # prepare\n",
    "    attributes = ['metro_id', 'time_stamp', 'ptr_ratio' ]\n",
    "    original_df = pd.read_csv(filename, encoding=\"ISO-8859-1\")\n",
    "    raw_df = original_df.drop(columns=['SizeRank'])\n",
    "    df_mat = []\n",
    "    def unwind(series):\n",
    "        # series: metro_id, RegionName, timestamp\n",
    "        # for metro info\n",
    "        metro_dict[series[1]] = series[0]\n",
    "        name_code = [ x.strip() for x in series[1].split(',') ]\n",
    "        metro_df_mat.append([ series[0], series[1], name_code[-1] ])\n",
    "        # for prt ratio info\n",
    "        metro_id = series[0]\n",
    "        for j in range(2, len(series)):\n",
    "            if pd.isnull(series[j]):\n",
    "                value = None\n",
    "            else:\n",
    "                value = series[j]\n",
    "            df_mat.append([ int(metro_id), series.index[j], value ])\n",
    "    # apply map\n",
    "    raw_df.apply(unwind, axis=1)\n",
    "    temp_df = pd.DataFrame(df_mat, columns=attributes)\n",
    "    # end time\n",
    "    print('time used to process ' + str(filename) + ': ' + str( int(time.time()-t0) ) + 's')\n",
    "    # return\n",
    "    return temp_df\n",
    "\n",
    "# for sale-to-list ratio\n",
    "def load_stl(filename, attributes):\n",
    "    # begin time\n",
    "    print('processing ' + filename)\n",
    "    t0 = time.time()\n",
    "    # prepare\n",
    "    attributes = ['metro_id', 'time_stamp', 'stl_ratio' ]\n",
    "    original_df = pd.read_csv(filename, encoding=\"ISO-8859-1\")\n",
    "    raw_df = original_df.drop(columns=['SizeRank','RegionType'])\n",
    "    df_mat = []\n",
    "    def unwind(series):\n",
    "        # series: metro_id, RegionName, timestamp\n",
    "        # for metro info\n",
    "        metro_dict[series[1]] = series[0]\n",
    "        name_code = [ x.strip() for x in series[1].split(',') ]\n",
    "        metro_df_mat.append([ series[0], series[1], name_code[-1] ])\n",
    "        # for prt ratio info\n",
    "        metro_id = series[0]\n",
    "        for j in range(2, len(series)):\n",
    "            if pd.isnull(series[j]):\n",
    "                value = None\n",
    "            else:\n",
    "                value = series[j]\n",
    "            df_mat.append([ int(metro_id), series.index[j], value ])\n",
    "    # apply map\n",
    "    raw_df.apply(unwind, axis=1)\n",
    "    temp_df = pd.DataFrame(df_mat, columns=attributes)\n",
    "    # end time\n",
    "    print('time used to process ' + str(filename) + ': ' + str( int(time.time()-t0) ) + 's')\n",
    "    # return\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/Metro_PriceToRentRatio_AllHomes.csv\n",
      "time used to process rawdata/Metro_PriceToRentRatio_AllHomes.csv: 2s\n",
      "processing rawdata/SaleToListRatio_Msa.csv\n",
      "time used to process rawdata/SaleToListRatio_Msa.csv: 1s\n"
     ]
    }
   ],
   "source": [
    "ptr_ratio_df = load_ptr('rawdata/Metro_PriceToRentRatio_AllHomes.csv', [])\n",
    "ptr_ratio_df.to_csv('processed_data/final_ptr_ratio.csv',index=False)\n",
    "\n",
    "stl_ratio_df = load_stl('rawdata/SaleToListRatio_Msa.csv', [])\n",
    "stl_ratio_df.to_csv('processed_data/final_stl_ratio.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load HomeValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_df(filename,property_type,room_num):\n",
    "    # begin time\n",
    "    print('processing ' + filename)\n",
    "    t0 = time.time()\n",
    "    # prepare\n",
    "    attributes = ['metro_id','property_type','time_stamp','room_num','price']\n",
    "    original_df = pd.read_csv(filename, encoding=\"ISO-8859-1\")\n",
    "    raw_df = original_df.drop(columns=['SizeRank'])\n",
    "    df_mat = []\n",
    "    def unwind(series):\n",
    "        # series: metro_id, RegionName, timestamp\n",
    "        # for metro info\n",
    "        metro_dict[series[1]] = series[0]\n",
    "        name_code = [ x.strip() for x in series[1].split(',') ]\n",
    "        metro_df_mat.append([ series[0], series[1], name_code[-1] ])\n",
    "        # for homevalue info\n",
    "        metro_id = series[0]\n",
    "        for j in range(2, len(series)):\n",
    "            if pd.isnull(series[j]):\n",
    "                price = None\n",
    "            else:\n",
    "                price = int(series[j])\n",
    "            if pd.isnull(room_num):\n",
    "                num = None\n",
    "            else:\n",
    "                num = int(room_num)\n",
    "            df_mat.append([ int(metro_id), property_type, series.index[j], num, price ])\n",
    "    # apply map\n",
    "    raw_df.apply(unwind, axis=1)\n",
    "    temp_df = pd.DataFrame(df_mat, columns=attributes)\n",
    "    # end time\n",
    "    print('time used to process ' + str(filename) + ': ' + str( int(time.time()-t0) ) + 's')\n",
    "    # return\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/HomeValues-Condo.csv\n",
      "time used to process rawdata/HomeValues-Condo.csv: 2s\n"
     ]
    }
   ],
   "source": [
    "homevalue_condo_df = load_to_df('rawdata/HomeValues-Condo.csv','condo',np.nan)\n",
    "homevalue_condo_df.to_csv('processed_data/processed_homevalue_condo.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/HomeValues-SingleFamily.csv\n",
      "time used to process rawdata/HomeValues-SingleFamily.csv: 5s\n"
     ]
    }
   ],
   "source": [
    "homevalue_sf_df = load_to_df('rawdata/HomeValues-SingleFamily.csv','singlefamily',np.nan)\n",
    "homevalue_sf_df.to_csv('processed_data/processed_homevalue_singlefamily.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/HomeValues-1bedroom.csv\n",
      "time used to process rawdata/HomeValues-1bedroom.csv: 3s\n"
     ]
    }
   ],
   "source": [
    "homevalue_1bedroom_df = load_to_df('rawdata/HomeValues-1bedroom.csv','1bedroom',1)\n",
    "homevalue_1bedroom_df.to_csv('processed_data/processed_homevalue_1bedroom.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/HomeValues-2bedroom.csv\n",
      "time used to process rawdata/HomeValues-2bedroom.csv: 4s\n"
     ]
    }
   ],
   "source": [
    "homevalue_2bedroom_df = load_to_df('rawdata/HomeValues-2bedroom.csv','2bedroom',2)\n",
    "homevalue_2bedroom_df.to_csv('processed_data/processed_homevalue_2bedroom.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/HomeValues-3bedroom.csv\n",
      "time used to process rawdata/HomeValues-3bedroom.csv: 4s\n"
     ]
    }
   ],
   "source": [
    "homevalue_3bedroom_df = load_to_df('rawdata/HomeValues-3bedroom.csv','3bedroom',3)\n",
    "homevalue_3bedroom_df.to_csv('processed_data/processed_homevalue_3bedroom.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/HomeValues-4bedroom.csv\n",
      "time used to process rawdata/HomeValues-4bedroom.csv: 4s\n"
     ]
    }
   ],
   "source": [
    "homevalue_4bedroom_df = load_to_df('rawdata/HomeValues-4bedroom.csv','4bedroom',4)\n",
    "homevalue_4bedroom_df.to_csv('processed_data/processed_homevalue_4bedroom.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save metro info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_df = pd.DataFrame(metro_df_mat, columns=['ID','name','state_code']).drop_duplicates(subset=['ID']).sort_values(by=['ID'])\n",
    "metro_df.to_csv('processed_data/final_metro.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load RentalPrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rental(filename,property_type,room_num,metro_dict):\n",
    "    # begin time\n",
    "    print('processing ' + filename)\n",
    "    t0 = time.time()\n",
    "    # prepare\n",
    "    attributes = ['metro_id','property_type','time_stamp','room_num','price']\n",
    "    original_df = pd.read_csv(filename)\n",
    "    raw_df = original_df.drop(columns=['SizeRank'])\n",
    "    df_mat = []\n",
    "    def unwind_rental(series):\n",
    "        if series[0] in metro_dict:\n",
    "            metro_id = metro_dict[series[0]]\n",
    "            for j in range(1, len(series)):\n",
    "                if pd.isnull(series[j]):\n",
    "                    price = None\n",
    "                else:\n",
    "                    price = int(series[j])\n",
    "                if pd.isnull(room_num):\n",
    "                    num = None\n",
    "                else:\n",
    "                    num = int(room_num)\n",
    "                df_mat.append([ metro_id, property_type, series.index[j], num, price ])\n",
    "    # apply map\n",
    "    raw_df.apply(unwind_rental, axis=1)\n",
    "    temp_df = pd.DataFrame(df_mat, columns=attributes)\n",
    "    # end time\n",
    "    print('time used to process ' + str(filename) + ': ' + str( int(time.time()-t0) ) + 's')\n",
    "    # return\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/Metro_MedianRentalPrice_CondoCoop.csv\n",
      "time used to process rawdata/Metro_MedianRentalPrice_CondoCoop.csv: 0s\n"
     ]
    }
   ],
   "source": [
    "rentalprice_condo_df = load_rental('rawdata/Metro_MedianRentalPrice_CondoCoop.csv','condo',np.nan,metro_dict)\n",
    "rentalprice_condo_df.to_csv('processed_data/processed_Metro_MedianRentalPrice_CondoCoop.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/Metro_MedianRentalPrice_Sfr.csv\n",
      "time used to process rawdata/Metro_MedianRentalPrice_Sfr.csv: 0s\n"
     ]
    }
   ],
   "source": [
    "rentalprice_sf_df = load_rental('rawdata/Metro_MedianRentalPrice_Sfr.csv','singlefamily',np.nan,metro_dict)\n",
    "rentalprice_sf_df.to_csv('processed_data/processed_Metro_MedianRentalPrice_Sfr.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/Metro_MedianRentalPrice_1Bedroom.csv\n",
      "time used to process rawdata/Metro_MedianRentalPrice_1Bedroom.csv: 0s\n"
     ]
    }
   ],
   "source": [
    "rentalprice_1bedroom_df = load_rental('rawdata/Metro_MedianRentalPrice_1Bedroom.csv','1bedroom',1,metro_dict)\n",
    "rentalprice_1bedroom_df.to_csv('processed_data/processed_Metro_MedianRentalPrice_1Bedroom.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/Metro_MedianRentalPrice_2Bedroom.csv\n",
      "time used to process rawdata/Metro_MedianRentalPrice_2Bedroom.csv: 0s\n"
     ]
    }
   ],
   "source": [
    "rentalprice_2bedroom_df = load_rental('rawdata/Metro_MedianRentalPrice_2Bedroom.csv','2bedroom',2,metro_dict)\n",
    "rentalprice_2bedroom_df.to_csv('processed_data/processed_Metro_MedianRentalPrice_2Bedroom.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/Metro_MedianRentalPrice_3Bedroom.csv\n",
      "time used to process rawdata/Metro_MedianRentalPrice_3Bedroom.csv: 0s\n"
     ]
    }
   ],
   "source": [
    "rentalprice_3bedroom_df = load_rental('rawdata/Metro_MedianRentalPrice_3Bedroom.csv','3bedroom',3,metro_dict)\n",
    "rentalprice_3bedroom_df.to_csv('processed_data/processed_Metro_MedianRentalPrice_3Bedroom.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rawdata/Metro_MedianRentalPrice_4Bedroom.csv\n",
      "time used to process rawdata/Metro_MedianRentalPrice_4Bedroom.csv: 0s\n"
     ]
    }
   ],
   "source": [
    "rentalprice_4bedroom_df = load_rental('rawdata/Metro_MedianRentalPrice_4Bedroom.csv','4bedroom',4,metro_dict)\n",
    "rentalprice_4bedroom_df.to_csv('processed_data/processed_Metro_MedianRentalPrice_4Bedroom.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "homevalue_df = pd.concat([homevalue_condo_df,\n",
    "                          homevalue_sf_df,\n",
    "                          homevalue_1bedroom_df,\n",
    "                          homevalue_2bedroom_df,\n",
    "                          homevalue_3bedroom_df,\n",
    "                          homevalue_4bedroom_df], ignore_index=True)\n",
    "homevalue_df.to_csv('processed_data/final_homevalue.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rentalprice_df = pd.concat([rentalprice_condo_df,\n",
    "                            rentalprice_sf_df,\n",
    "                            rentalprice_1bedroom_df,\n",
    "                            rentalprice_2bedroom_df,\n",
    "                            rentalprice_3bedroom_df,\n",
    "                            rentalprice_4bedroom_df], ignore_index=True)\n",
    "rentalprice_df.to_csv('processed_data/final_rentalprice.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
